{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving a counterintuitive probability problem with Markov chains\n",
    "\n",
    "The weekly Riddler column at FiveThirtyEight posted a **[fascinating (and delicious) chocolate-based probability question](https://fivethirtyeight.com/features/can-you-eat-all-the-chocolates/)**:\n",
    "\n",
    ">I have 10 chocolates in a bag: Two are milk chocolate, while the other eight are dark chocolate. One at a time, I randomly pull chocolates from the bag and eat them — that is, until I pick a chocolate of the other kind. When I get to the other type of chocolate, I put it back in the bag and start drawing again with the remaining chocolates. I keep going until I have eaten all 10 chocolates.\n",
    "\n",
    "> For example, if I first pull out a dark chocolate, I will eat it. (I’ll always eat the first chocolate I pull out.) If I pull out a second dark chocolate, I will eat that as well. If the third one is milk chocolate, I will not eat it (yet), and instead place it back in the bag. Then I will start again, eating the first chocolate I pull out.\n",
    "\n",
    "> What are the chances that the last chocolate I eat is milk chocolate?\n",
    "\n",
    "Before starting work, I took an intuitive guess. With 20% of the bag started off as milk chocolate, I figured that the probability of ending in milk was greater than 20% because of the \"incumbency disadvantage\" – chocolates with a higher porportion are more likely to be picked. I also estimated an upper bound of 50% because the dark chocolates had to be more likely than the milk chocolates. For a single point estimate, I averaged the upper and lower bound for a guess of 35%.\n",
    "\n",
    "What was the answer? As it turns out, **the probability of eating a milk chocolate last is 50%!** In fact, while the code below does not offer an inductive proof of the general case, it looks that any starting distribution of milk and dark chocolates result in an equal probability of being selected last. That is, whether the starting distribution is 2 milk and 8 dark or 2 milk and 30 dark, milk still has a 50% probability of being last!\n",
    "\n",
    "How did we get there? Below, I'll walk through my Markov chain approach implemented in Python to solve the problem, and subsequently confirm the result with a Monte Carlo simulation. While there simpler approaches to solve the problem (e.g., dynamic programming), taking the roundabout route and being able to draw out the full transition matrix between states has a certain completeness (if lacking elegance).\n",
    "\n",
    "\n",
    "## Framework of state transitions\n",
    "\n",
    "We can think about the problem as a transition between *states*. At any point, the bag of chocolates is in a certain state, and this state determines the probabilities of transitioning to any other series of states. Each state represents three pieces of information: the number of remaining milk chocolates, the number of remaining dark chocolates, and what types of chocolate can be eaten in the next state. What do we mean by that last point? Each state meets one of three conditions:\n",
    "\n",
    "- A milk chocolate was just eaten, so only a milk chocolate can be eaten in the next state. If a dark chocolate is selected, it will be returned to the bag.\n",
    "- A dark chocolate was just eaten, so only a dark chocolate can be eaten in the next state. If a milk chocolate is selected, it will be returned to the bag.\n",
    "- The bag has been \"reset\" and either milk or dark can be eaten next. \n",
    "\n",
    "We'll call the first condition \"m\" (milk), we'll call the condition state \"d\" (dark), and the last condition \"r\" (reset). We'll name each state by filling in the shorthand $x$|$y$|$c$, where $x$ denotes the number of milk chocolates, $y$ denotes the number of dark chocolates, and $c$ denotes the current condition of the bag. For example, $2$|$2$|$r$ represents a bag that currently has two milk chocolates, two dark chocolates, and is in the reset state.  \n",
    "\n",
    "Now that we know how to describe each state, we can start thinking about how states transition to other states, and the associated probabilities.  If the bag is in state $2$|$2$|$r$, what states can it transition to, and with what frequency?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"markov_files/fig1.png\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're in a \"reset\" condition, so either milk chocolate or dark chocolate can be eaten next. Because there are an equal number of milk and dark chocolates, they are eaten with equal probability, resulting in a 50% chance of state $1$|$2$|$m$ and state $2$|$1$|$d$.\n",
    "\n",
    "What happens when we go down one more level?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"markov_files/fig2.png\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're in state $1$|$2$|$m$, there are three chocolates left in the bag, and we have a 1/3 chance of drawing a milk chocolate, and a 2/3 chance of drawing a dark chocolate. If we draw a milk chocolate, we eat a milk chocolate, leading to state $0$|$2$|$m$. If we draw a dark chocolate, we don't eat any chocolate, and transition to the reset state $1$|$2$|$r$. The right half of the tree follows a similar logic.\n",
    "\n",
    "Now with this framework of state transition in mind, we can talk about Markov chains and the solution to the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation: Using Markov chains\n",
    "\n",
    "Our diagram above above is an example of a **Markov chain**: a model of a potential sequence of states and the associated probabilities of transitioning between states. The key condition for a process to be a *Markov process* is that the probability of the next state depends only on the current state. This is true in our Markov model because each of our states includes whether we are in an $m$, $d$, or $r$ condition, and so encodes the necessary information to generate the transitions without looking backward. \n",
    "\n",
    "The full set of possible transitions and their probabilities is known as a transition matrix. Our transition matrix will start on the $2$|$8$|$r$, as described in the problem instructions. Our final states in the model will have no chocolates left. There are two potential final states of the model, $0$|$0$|$m$ and $0$|$0$|$d$, denoting whether the last chocolate was milk or dark when we have no chocolates remaining. These final states are known in Markov parlance as *absorbing states*. Once these states are reached, they cannot be left, so the Markov process is over. As it happens, our Markov chain also has the property that once any particular state is reached, it will not be reached again (except for absorbing states).\n",
    "\n",
    "We want to construct the transition matrix because once we have it, we can run some (relatively simple) linear algebra operations, and the result will tell us the probability of transitioning to each of the two absorbing states from any possible state, answering the problem!\n",
    "\n",
    "The transition matrix will be an $N \\times N$ matrix, where $N$ represents the number of potential states. Each row represents a state, and the value in each column represents the probability of transitioning to the state that matches in the index of that column. Here is the transition matrix for the smaller sequence starting with $2$|$2$|$r$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"markov_files/fig3.png\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top left white cell at the intersection of $2$|$2$|$r$ is 0 because state $2$|$2$|$r$ has a 0% probability of transitioning to $2$|$2$|$r$ (itself). However, it has a 50% probability of transitioning to $2$|$1$|$d$. Highlighted in yellow are the absorbing states. Each absorbing state has a 100% probability of transitioning to itself.\n",
    "\n",
    "Most of the cells in the matrix will be 0 because each state only has a nonzero probability of transitioning to either one or two other states.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the transition matrix\n",
    "\n",
    "Now we get to the fun. The image above was a sample; we need to generate the full transition starting with $2$|$8$|$r$ (in fact, we will generalize the code, such that it will generate the transition matrix for any starting state). We'll do this via a Python script that finds, for each state, the possible states it can transition to. We can do this fairly simply because the rules are deterministic, and each state can transition to either one or two other states (i.e., only milk chocolate or dark chocolate can be picked from the bag, and we know the probabilities from the ratio of milk chocolate to dark chocolate). \n",
    "\n",
    "In the code (available below), we began by generating the two possible states resulting from $2$|$8$|$r$, which are $1$|$8$|$m$ (with probability 20%), and $2$|$7$|$d$ (with probability 80%). We then treat these new states as an input, and generate the new states that can result from these states. For instance, $2$|$7$|$d$ can generate either $2$|$7$|$r$ or $2$|$6$|$d$. We loop and repeat this process of generating states until we have generated all possible states. \n",
    "\n",
    "What results is a $68 \\times 68$ matrix containing 4,624 cells (with most of them equal to zero). We can then use this matrix to find the probability of eating a milk chocolate last.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding absorption probabilities from each starting state\n",
    "\n",
    "We can perform linear algebra to find a matrix $B$ that contains, for each state (not just the starting state), the probability of transitioning to each of the two absorbing states. The solution formula and proof is given in chapter 3 of [*Finite Markov Chains*](https://docs.ufpr.br/~lucambio/CE222/1S2014/Kemeny-Snell1976.pdf) by Kemeny and Snell (1960).\n",
    "\n",
    "Given that:\n",
    "- $Q$ represents a matrix containing the non-absorbing states of the full transition matrix\n",
    "- $I$ is the [identity matrix](https://en.wikipedia.org/wiki/Identity_matrix) of $Q$\n",
    "- $R$ is a matrix containing rows for each of the non-absorbing states and columns for each of the absorbing states\n",
    "\n",
    "$B$ = $(Q - I)^{-1} \\times R$\n",
    "\n",
    "Because we sorted our transition matrix, the first cell (index [0,0]) of $B$ will be the probability of ending in the absorbing state $0$|$0$|$m$ from initial state $2$|$8$|$r$. This single value is what is returned by our Python model coded below. We can use the function build_model(m = starting milk chocolates, d = starting dark chocolates) to run the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_model(2,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other initial starting conditions also return a probability of 50%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_model(4,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_model(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_model(20,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first I couldn't believe the 50% probability! I wrote a Monte Carlo simulation (also given below) to confirm the result. It's certainly a counteruntuitive result and I don't yet have an elegant explanation of why this is the case. I'm looking forward to the Riddler's solutions writeup next week and learning more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Markov transition model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def build_model(m: int, d: int):\n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    \n",
    "    m (int): The number of milk chocolates starting in the bag. Must be greater than 0.\n",
    "    d (int): The number of dark chocolates starting in the bag. Must be greater than 0.\n",
    "    \n",
    "    Assumes the starting state is \"reset\", e.g., either chocolate can be selected\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    p (float): Probability of milk chocolate being the last chocolate in the bag\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    We need to start by building the transition matrix. We'll use the function 'add_to_transitions_list' to build the first two entries on the list from the starting state. \n",
    "    \n",
    "    We refer to each state by a shorthand name, m|d|s, meaning 'milk', 'chocolate', 'state'.\n",
    "    \n",
    "    For example '2|7|d' refers to a state of 2 milk chocolates left in the bag, 7 dark chocolates, and that the last draw from the bag resulted in a dark chocolate (d). For each state, we want to find the states that it transitions to, adn the associated probabilities of each potential state.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    assert m > 0 and d > 0, \"m and d arguments must be greater than 0\"\n",
    "\n",
    "    \n",
    "    transitions = []\n",
    "    add_to_transitions_list(m,d,'r',transitions)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    Each transition list generates output states. We iteratively want to treat these output states as inputs to generate the output states from these new states.\n",
    "    \n",
    "    We'll repeat this process (iteratively adding elements to a list of transitions and probabilities), until there are no more elements to add to the list.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialization of tracker of list length\n",
    "    trans_len = 1\n",
    "\n",
    "    # Stop generating the sequence when it doesn't have add any more rows each iteration\n",
    "    while len(transitions) > trans_len:\n",
    "\n",
    "        trans_len = len(transitions)\n",
    "\n",
    "        # New sequence to generate is in seventh element of list\n",
    "        # Generate as long as there are chocolates remaining (4th or 5th element is greater than 0)\n",
    "        new_seqs = [j[7] for j in transitions if j[7] not in [i[0] for i in transitions] and max(j[4],j[5]) > 0]\n",
    "        for i in new_seqs:\n",
    "            add_to_transitions_list(int(i.split('|')[0]),int(i.split('|')[1]),i.split('|')[2],transitions)\n",
    "            \n",
    "        # Reset\n",
    "        new_seqs = []\n",
    "        \n",
    "    \"\"\" \n",
    "    \n",
    "    Our absorbing states are missing from the transition list. We'll add these, then we'll do some cleaning to actually convert our list of transitions into a Markov transition matrix.\n",
    "        \n",
    "    \"\"\"    \n",
    "        \n",
    "    # Add absorbing states\n",
    "    transitions.append(['0|0|m', 0, 0, 'm', 0, 0, 'm', '0|0|m', 1])\n",
    "    transitions.append(['0|0|d', 0, 0, 'm', 0, 0, 'm', '0|0|d', 1])\n",
    "    \n",
    "    # Convert to matrix format\n",
    "    df = pd.DataFrame(transitions,columns = ['identifier','milk_remaining', 'dark_remaining', 'state','milk_remaining_new','dark_remaining_new','state_new','identifier_new','p'])\n",
    "    df = df.drop_duplicates()\n",
    "    df_pivot = df.pivot_table(index='identifier', columns='identifier_new', values='p',fill_value=0,dropna=False)\n",
    "\n",
    "    # Rectangularize the matrix \n",
    "    df_pivot[str(m) + '|' + str(d) + '|r'] = 0\n",
    "    \n",
    "    # Sort rows and columns\n",
    "    df_pivot = df_pivot.sort_index(ascending=False)\n",
    "    df_pivot = df_pivot.sort_index(ascending=False,axis=1)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Matrix algebra to find the probability of absorption from each state\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # 2 appears because it represents the number of absorbing states\n",
    "    \n",
    "    matrix = df_pivot.to_numpy()\n",
    "    \n",
    "    I = np.eye(len(matrix) - 2)  \n",
    "    Q = matrix[:-2, :-2]\n",
    "    R = matrix[:-2,-2:]\n",
    "\n",
    "    # And the answer is ... (probability of ending in milk from the initial state)\n",
    "    return round(np.matmul(np.linalg.inv(I - Q), R)[0][0],6)\n",
    "\n",
    "\n",
    "def add_to_transitions_list(m,d,state,transitions): \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Function takes in an input state and adds the output states and probabilities to a transition list for each of those states.\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "    m (int): The number of milk chocolates currently in the bag\n",
    "    d (int): The number of dark chocolates currently in the bag\n",
    "    state (str): Either 'm', 'd', or 'r', representing the state before transition\n",
    "    transitions (list): List to append transitions to\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    This function finds the transitions from any state. We use the knowledge that there are only two potential transitions (one for milk being selected and one for dark being selected). \n",
    "    \n",
    "     If previous selection was milk, the only two results are \"milk\" and \"reset\"\n",
    "     If previous selection was dark, the only two results are \"dark\" and \"reset\"\n",
    "     If previous selection was reset, the only two results are \"milk\" and \"dark\"\n",
    "     \n",
    "    \"\"\"   \n",
    "    # What happens if next draw is milk?\n",
    "    \n",
    "    m_new = m if state == 'd' else m-1\n",
    "    d_new = d\n",
    "    p = m/(m+d)\n",
    "    \n",
    "    if state == 'm':\n",
    "        state_new = 'm'\n",
    "    elif state == 'd':\n",
    "        state_new = 'r'\n",
    "    elif state == 'r':\n",
    "        state_new = 'm'       \n",
    "    \n",
    "    if p > 0:\n",
    "        append_transitions(m,d,state,m_new,d_new,state_new,p,transitions)\n",
    "        \n",
    "    # What happens if next draw is dark?\n",
    "\n",
    "    m_new = m\n",
    "    d_new = d if state == 'm' else d-1\n",
    "    p = 1 - (m/(m+d))\n",
    "    \n",
    "    if state == 'm':\n",
    "        state_new = 'r'\n",
    "    elif state == 'd':\n",
    "        state_new = 'd'\n",
    "    elif state == 'r':\n",
    "        state_new = 'd'\n",
    "    \n",
    "    # Choose dark\n",
    "    if p > 0:\n",
    "        append_transitions(m,d,state,m_new,d_new,state_new,p,transitions)\n",
    "\n",
    "        \n",
    "def append_transitions(m,d,state,m_new,d_new,state_new,p,transitions):\n",
    "\n",
    "    \"\"\"   \n",
    "    \n",
    "    Function appends collected information about a transition to a list.\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "    m (int): The number of milk chocolates currently in the bag\n",
    "    d (int): The number of dark chocolates currently in the bag\n",
    "    state (str): Either 'm', 'd', or 'r', representing the state before transition\n",
    "    transitions (list): List to append transitions to\n",
    "    m_new (int): The number of milk chocolates currently in the bag after transition\n",
    "    d_new (int): The number of dark chocolates currently in the bag after transition\n",
    "    state_new (str): Either 'm', 'd', or 'r', representing the after before transition\n",
    "    p (float): Probability of this transition occurring\n",
    "        \n",
    "    \"\"\"\n",
    "    transitions.append([ \n",
    "                     str(m) + '|' + str(d) + '|' + state\n",
    "                    ,m\n",
    "                    ,d\n",
    "                    ,state\n",
    "                    ,m_new\n",
    "                    ,d_new\n",
    "                    ,state_new \n",
    "                    ,str(m_new) + '|' + str(d_new) + '|' + state_new\n",
    "                    ,p \n",
    "                    ])        \n",
    "\n",
    "print(build_model(2,8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49974\n"
     ]
    }
   ],
   "source": [
    "# Monte Carlo simulation\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "def find_last_chocolate(chocolates):\n",
    "    prev_selection = -1\n",
    "    while len(chocolates) > 1:\n",
    "        i = random.sample(chocolates,1)[0]\n",
    "        if prev_selection != i and prev_selection != -1:\n",
    "            prev_selection = -1\n",
    "        else:\n",
    "            prev_selection = i\n",
    "            chocolates.remove(i)\n",
    "    return chocolates[0]\n",
    "\n",
    "iters = 1000000\n",
    "i = 0\n",
    "for _ in range(iters):\n",
    "    i = i + find_last_chocolate([1,1,0,0,0,0,0,0,0,0])\n",
    "print(i/iters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
